# A Simple Multi-armed Bandits Class and 3 Policies

This repository contains some supplementary code I wrote to demonstrate the beta-Bernoulli Multi-armed Bandits problem and three exploitation/exploration policies (eGreedy, UCB, Thompson). Everything is pretty rudimentary, but fun to play around with. 

The motivation for producing this code came from a paper presentation I gave as a part of a course. The presentation slides are also included in this repository, which discuss a very interesting application of MABs and Thompson sampling.

## Dependencies
- Python 3.8
- Numpy 1.20
- Matplotlib 3.3
